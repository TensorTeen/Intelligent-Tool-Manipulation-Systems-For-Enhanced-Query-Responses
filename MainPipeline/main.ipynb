{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import *\n",
    "from pipeline import Pipeline, PipeConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('devrev_tools.json') as f:\n",
    "    tools = json.load(f)\n",
    "\n",
    "with open('devrev_data.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"query\": \"Allocate the work items I own that are at the 'QA' stage and with 'medium' severity to the current sprint, after prioritizing and summarizing them.\",\n",
    "        \"solution\": [\n",
    "            {\n",
    "                \"tool_name\": \"who_am_i\",\n",
    "                \"arguments\": []\n",
    "            },\n",
    "            {\n",
    "                \"tool_name\": \"works_list\",\n",
    "                \"arguments\": [\n",
    "                    {\n",
    "                        \"argument_name\": \"owned_by\",\n",
    "                        \"argument_value\": [\"$$PREV[0]\"]\n",
    "                    },\n",
    "                    {\n",
    "                        \"argument_name\": \"stage.name\",\n",
    "                        \"argument_value\": [\"QA\"]\n",
    "                    },\n",
    "                    {\n",
    "                        \"argument_name\": \"type\",\n",
    "                        \"argument_value\": [\"ticket\"]\n",
    "                    },\n",
    "                    {\n",
    "                        \"argument_name\": \"ticket.severity\",\n",
    "                        \"argument_value\": [\"medium\"]\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"tool_name\": \"prioritize_objects\",\n",
    "                \"arguments\": [\n",
    "                    {\n",
    "                        \"argument_name\": \"objects\",\n",
    "                        \"argument_value\": \"$$PREV[2]\"\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"tool_name\": \"summarize_objects\",\n",
    "                \"arguments\": [\n",
    "                    {\n",
    "                        \"argument_name\": \"objects\",\n",
    "                        \"argument_value\": \"$$PREV[3]\"\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"tool_name\": \"get_sprint_id\",\n",
    "                \"arguments\": []\n",
    "            },\n",
    "            {\n",
    "                \"tool_name\": \"add_work_items_to_sprint\",\n",
    "                \"arguments\": [\n",
    "                    {\n",
    "                        \"argument_name\": \"work_ids\",\n",
    "                        \"argument_value\": \"$$PREV[1]\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"argument_name\": \"sprint_id\",\n",
    "                        \"argument_value\": \"$$PREV[2]\"\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"query\": \"Create actionable tasks from the summary of all 'high' severity tickets associated with 'REV-456', get similar work items to those tasks, prioritize by severity, and filter out those that don't need immediate action.\",\n",
    "        \"solution\": [\n",
    "            {\n",
    "                \"tool_name\": \"works_list\",\n",
    "                \"arguments\": [\n",
    "                    {\n",
    "                        \"argument_name\": \"ticket.severity\",\n",
    "                        \"argument_value\": [\"high\"]\n",
    "                    },\n",
    "                    {\n",
    "                        \"argument_name\": \"ticket.rev_org\",\n",
    "                        \"argument_value\": [\"REV-456\"]\n",
    "                    },\n",
    "                    {\n",
    "                        \"argument_name\": \"type\",\n",
    "                        \"argument_value\": [\"ticket\"]\n",
    "                    },\n",
    "                    {\n",
    "                        \"argument_name\": \"ticket.needs_response\",\n",
    "                        \"argument_value\": True\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"tool_name\": \"summarize_objects\",\n",
    "                \"arguments\": [\n",
    "                    {\n",
    "                        \"argument_name\": \"objects\",\n",
    "                        \"argument_value\": \"$$PREV[0]\"\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"tool_name\": \"create_actionable_tasks_from_text\",\n",
    "                \"arguments\": [\n",
    "                    {\n",
    "                        \"argument_name\": \"text\",\n",
    "                        \"argument_value\": \"$$PREV[1]\"\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"tool_name\": \"get_similar_work_items\",\n",
    "                \"arguments\": [\n",
    "                    {\n",
    "                        \"argument_name\": \"work_id\",\n",
    "                        \"argument_value\": \"$$PREV[2]\"\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"tool_name\": \"prioritize_objects\",\n",
    "                \"arguments\": [\n",
    "                    {\n",
    "                        \"argument_name\": \"objects\",\n",
    "                        \"argument_value\": \"$$PREV[3]\"\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline-1: GPT-3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(PipeConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import litellm\n",
    "litellm.set_verbose=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Prioritize open tasks, find similar work items for the task and create tasks based on their summary.\"\n",
    "output = pipe(query,tools,examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embed_calls': 1,\n",
       " 'return_tools': [],\n",
       " 'solution': {'query': 'Prioritize open tasks, find similar work items for the task and create tasks based on their summary.',\n",
       "  'solution': [{'tool_name': 'works_list',\n",
       "    'arguments': [{'argument_name': 'status', 'argument_value': ['open']},\n",
       "     {'argument_name': 'type', 'argument_value': ['task']}]},\n",
       "   {'tool_name': 'get_similar_work_items',\n",
       "    'arguments': [{'argument_name': 'work_id',\n",
       "      'argument_value': '$$PREV[0]'}]},\n",
       "   {'tool_name': 'summarize_objects',\n",
       "    'arguments': [{'argument_name': 'objects',\n",
       "      'argument_value': '$$PREV[1]'}]},\n",
       "   {'tool_name': 'create_actionable_tasks_from_text',\n",
       "    'arguments': [{'argument_name': 'text', 'argument_value': '$$PREV[2]'}]}]},\n",
       " 'time_taken': 5.324092149734497,\n",
       " 'openai_model': 'gpt-3.5-turbo-1106',\n",
       " 'embedding_model': 'text-embedding-ada-002',\n",
       " 'num_embedding_tokens_query': 20,\n",
       " 'num_embedding_tokens_tool': 0,\n",
       " 'num_output_tokens': 244,\n",
       " 'num_input_tokens': 1095,\n",
       " 'embedding_cost_query': 2.0000000000000003e-06,\n",
       " 'embedding_cost_tool': 0.0,\n",
       " 'gpt_input_cost': 0.003285,\n",
       " 'gpt_output_cost': 0.001464,\n",
       " 'total_inference_cost': 0.004751,\n",
       " 'tool_setup_cost': 0.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import *\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "class Retriever:\n",
    "    def __init__(self, model_name):\n",
    "        self.model_name = model_name\n",
    "        self._tools = []\n",
    "        self._tool_names = set()\n",
    "\n",
    "    def embed(self, texts):\n",
    "        # Assuming EmbeddingBackend accepts a list of texts and returns a list of embeddings\n",
    "        embeddings_data = EmbeddingBackend(self.model_name, texts).data\n",
    "        return np.array([item['embedding'] for item in embeddings_data])\n",
    "\n",
    "    def get_doc(self, tool):\n",
    "        s = tool['tool_description']\n",
    "        for arg in tool['args']:\n",
    "            s += ' ' + arg['arg_description']\n",
    "        return s\n",
    "\n",
    "    def index(self, tools):\n",
    "        tools = copy.deepcopy(tools)\n",
    "        embed_calls = 0\n",
    "        new_tools = [tool for tool in tools if tool['tool_name'] not in self._tool_names]\n",
    "        embed_calls += len(new_tools) \n",
    "        # Extract documents from new tools\n",
    "        docs_to_embed = [self.get_doc(tool) for tool in new_tools]\n",
    "        docs_embeded = ' '.join(docs_to_embed)\n",
    "        if not docs_to_embed:return 0, []\n",
    "        # Get embeddings for all new documents in one batch\n",
    "        embeddings = self.embed(docs_to_embed)\n",
    "        \n",
    "        \n",
    "        # Assign the corresponding embedding to each tool and update internal structures\n",
    "        for i, tool in enumerate(new_tools):\n",
    "            tool['embedding'] = embeddings[i]\n",
    "            self._tool_names.add(tool['tool_name'])\n",
    "            self._tools.append(tool)\n",
    "        return embed_calls,docs_embeded\n",
    "\n",
    "    def embedding_similarity(self, query_embedding, tool_embedding):\n",
    "        return (query_embedding.T @ tool_embedding)\n",
    "\n",
    "    def __call__(self, query, tools=None, k=8):\n",
    "        if tools is not None:\n",
    "            embed_calls,docs_embeded = self.index(tools)\n",
    "                    \n",
    "        query_embed = self.embed([query])[0]  # Embed the single query text\n",
    "        embed_calls+=1\n",
    "        query_embeded = query\n",
    "        \n",
    "        # Calculate similarity scores between the query embedding and all indexed tools' embeddings.\n",
    "        for tool in self._tools:\n",
    "            tool['similarity'] = self.embedding_similarity(query_embed, tool['embedding'])\n",
    "            \n",
    "         # Sort tools by similarity score and filter out those that are not part of the input 'tools' if provided.\n",
    "        return_tools = sorted(self._tools,key=lambda x: x['similarity'],reverse=True).copy()\n",
    "        if tools is not None:\n",
    "            return_tools = [tool for tool in return_tools if tool in tools]\n",
    "        return {'embed_calls':embed_calls,\n",
    "                'return_tools':return_tools[:k],\n",
    "                'query_embeded':query_embeded,\n",
    "                'docs_embeded':docs_embeded}\n",
    "\n",
    "    @staticmethod\n",
    "    def strip_embeddings(tools):\n",
    "       stripped_tools = copy.deepcopy(tools)\n",
    "       for tool in stripped_tools:\n",
    "           del tool['embedding']\n",
    "           del tool['similarity']\n",
    "       return stripped_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(texts):\n",
    "    # Assuming EmbeddingBackend accepts a list of texts and returns a list of embeddings\n",
    "    embeddings_data = EmbeddingBackend(PipeConfig.embedding_model, texts).data\n",
    "    return np.array([item['embedding'] for item in embeddings_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in data:\n",
    "    query['embed'] = embed([query['query']])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prioritize my P0 issues and add them to the current sprint 0.9820559665613069\n",
      "Given a customer meeting transcript T , create action items and add them to my current sprint 0.8447304038034076\n",
      "Get all work items similar to TKT-123, summarize them, create issues from that summary, and prioritize them 0.8161371033004452\n",
      "What are my all issues in the triage stage under part FEAT-123? Summarize them. 0.8020886654641636\n",
      "Summarize work items similar to don:core:dvrv-us-1:devo/0:issue/1 0.7932433821950118\n",
      "Summarize high severity tickets from the customer UltimateCustomer 0.7864176972938117\n",
      "List all high severity tickets coming in from slack from customer Cust123 and generate a summary of them. 0.7665894492504293\n",
      "What is the meaning of life? 0.7144496811530685\n"
     ]
    }
   ],
   "source": [
    "new_query = 'Prioritise my top P0 issues and add them to the current sprint'\n",
    "new_query_embed = embed([new_query])[0]\n",
    "scores = []\n",
    "for query in data:\n",
    "    scores.append(query['embed'].T @ new_query_embed)\n",
    "idx = np.argsort(scores)[::-1]\n",
    "for i in idx:\n",
    "    print(data[i]['query'],scores[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'examples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/ch20b103sivasankar/Documents/DevRev_Submission/AryaPipe/main.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ch20b103sivasankar/Documents/DevRev_Submission/AryaPipe/main.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m examples[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'examples' is not defined"
     ]
    }
   ],
   "source": [
    "examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleRetreiev"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
